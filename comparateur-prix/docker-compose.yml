version: '3.8'
#Base de donnÃ©es
services:
  db:
    build: ./db
    environment:
      MYSQL_ROOT_PASSWORD: toto
      MYSQL_DATABASE: Produits
      MYSQL_USER: toto
      MYSQL_PASSWORD: toto
    volumes:
      - db_data:/var/lib/mysql
    networks:
      - mon_reseau

  # Scraper
  # 1) Scraper : lance les spiders automatiquement
  scraper:
    build: ./scraper
    depends_on:
      - db
    volumes:
      - ./scraper:/app
    working_dir: /app/comparateur
    command: >
      sh -c "
      rm -f output/.done &&
      mkdir -p output &&
      scrapy crawl produits_decitre &&
      scrapy crawl produits_eyrolles &&
      scrapy crawl produits_mollat &&
      touch output/.done
      "
    networks:
      - mon_reseau
    restart: "no"

  # 2) Streamlit : attend la fin du scraping puis lance l'interface
  streamlit:
    build: ./scraper
    container_name: comparateur_streamlit
    depends_on:
      - db
    volumes:
      - ./scraper:/app
    working_dir: /app/comparateur
    ports:
      - "8501:8501"
    command: streamlit run app.py --server.address=0.0.0.0 --server.port=8501
    networks:
      - mon_reseau

  # (Optionnel) phpMyAdmin si tu l'utilises
  phpmyadmin:
    image: phpmyadmin/phpmyadmin
    container_name: phpmyadmin
    depends_on:
      - db
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      PMA_PORT: 3306
    networks:
      - mon_reseau

volumes:
  db_data:

networks:
  mon_reseau: