# ğŸ“š Comparateur de Prix de Livres - Web Scraping Project

Ce projet est un comparateur de prix de livres automatisÃ©. Il utilise **Python** et le framework **Scrapy** pour extraire des donnÃ©es de plusieurs librairies en ligne (Decitre, Eyrolles, Mollat, etc.), les nettoie et les stocke dans une base de donnÃ©es **MySQL**.

L'ensemble de l'architecture est conteneurisÃ© avec **Docker** pour un dÃ©ploiement facile et reproductible.

## ğŸš€ FonctionnalitÃ©s

* **Extraction de donnÃ©es (Scraping) :** RÃ©cupÃ©ration automatique du titre, du prix et du lien des livres.
* **Multi-sites :** Architecture capable de gÃ©rer plusieurs sites web via des "Spiders" dÃ©diÃ©s (ex: `produits_decitre.py`, `eyrolles.py`).
* **Nettoyage de donnÃ©es (Pipeline) :** Conversion des prix (chaÃ®nes de caractÃ¨res vers flottants), suppression des symboles devises, etc.
* **Stockage Persistant :** Sauvegarde automatique dans une base de donnÃ©es MySQL.
* **Interface d'administration :** Visualisation des donnÃ©es via PhpMyAdmin.
* **Infrastructure Docker :** Lancement de la BDD, du Scraper et de l'interface Admin en une seule commande.

## ğŸ› ï¸ Technologies utilisÃ©es

* **Langage :** Python 3.9+
* **Framework de Scraping :** Scrapy
* **Base de donnÃ©es :** MySQL 5.7
* **Connecteur :** mysql-connector-python
* **Administration BDD :** PhpMyAdmin
* **Conteneurisation :** Docker & Docker Compose

## ğŸ“‚ Structure du Projet

```text
.
â”œâ”€â”€ docker-compose.yml      # Orchestration des conteneurs (DB, Scraper, Admin)
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ Dockerfile          # Configuration de l'image MySQL
â”‚   â””â”€â”€ creation.sql        # Script d'initialisation de la table 'Livre'
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ Dockerfile          # Configuration de l'image Python/Scrapy
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”‚   â”œâ”€â”€ scrapy.cfg          # Config globale Scrapy
â”‚   â””â”€â”€ comparateur/        # Code source du Scrapy
â”‚       â”œâ”€â”€ items.py        # DÃ©finition de la structure des donnÃ©es
â”‚       â”œâ”€â”€ pipelines.py    # Traitement et insertion SQL
â”‚       â”œâ”€â”€ settings.py     # RÃ©glages du robot (User-Agent, dÃ©lais...)
â”‚       â””â”€â”€ spiders/        # Les robots (un fichier par site)
â”‚           â”œâ”€â”€ produits_decitre.py
â”‚           â”œâ”€â”€ produits_eyrolles.py
â”‚           â””â”€â”€ produits_mollat.py

```

## ğŸ“‹ PrÃ©requis

* [Docker Desktop](https://www.docker.com/products/docker-desktop/) installÃ© sur votre machine.
* Git (pour cloner le projet).

## âš™ï¸ Installation et Lancement

1. **Cloner le dÃ©pÃ´t :**
```bash
git clone [https://github.com/FaridaSintondji/webscraping.git](https://github.com/FaridaSintondji/webscraping.git)
cd webscraping

```


2. **Lancer l'application :**
Cette commande construit les images et lance les conteneurs en arriÃ¨re-plan.
```bash
docker compose up --build -d

```


3. **VÃ©rifier le fonctionnement :**
Le scraper se lance automatiquement au dÃ©marrage. Vous pouvez suivre sa progression avec :
```bash
docker compose logs -f scraper

```


4. **Voir les donnÃ©es (PhpMyAdmin) :**
Ouvrez votre navigateur et allez sur :
ğŸ‘‰ **http://localhost:8081**
* **Serveur :** db
* **Utilisateur :** toto
* **Mot de passe :** toto
* **Base de donnÃ©es :** Produits -> Table `Livre`



## ğŸ›‘ Commandes Utiles

* **ArrÃªter les conteneurs :**
```bash
docker compose down

```


* **RÃ©initialiser la base de donnÃ©es (Grand nettoyage) :**
Si vous avez modifiÃ© la structure de la table ou si vous voulez effacer toutes les donnÃ©es pour repartir de zÃ©ro :
```bash
docker compose down -v  # Le -v supprime le volume de donnÃ©es
docker compose up --build -d

```


* **Relancer uniquement le scraper (sans Ã©teindre la BDD) :**
```bash
docker compose restart scraper

```



## ğŸ“ SchÃ©ma de la Base de DonnÃ©es

La table `Livre` est structurÃ©e comme suit :

| Colonne | Type | Description |
| --- | --- | --- |
| id | INT (PK) | Identifiant unique (Auto-inc) |
| titre | TEXT | Titre du livre |
| prix | FLOAT | Prix du livre (ex: 19.50) |
| url | TEXT | Lien vers la page produit |
| site | VARCHAR(50) | Source (ex: "Decitre", "Eyrolles") |

## ğŸ‘¥ Auteurs

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du cours de Web Scraping & NoSQL.

* **Farida SINTONDJI**
* **AÃ¯da DIARRASSOUBA**
* **Yomn GERALDO ASSANI**

---

*DerniÃ¨re mise Ã  jour : DÃ©cembre 2025*

```


C'est du trÃ¨s bon travail d'Ãªtre arrivÃ©e jusqu'au bout de ce projet avec Docker et Scrapy ! ğŸ‘

```
