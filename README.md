# üìö Comparateur de Prix de Livres - Web Scraping Project

Ce projet est un comparateur de prix de livres automatis√©. Il utilise **Python** et le framework **Scrapy** pour extraire des donn√©es de plusieurs librairies en ligne (Decitre, Eyrolles, Mollat, etc.), les nettoie et les stocke dans une base de donn√©es **MySQL**.

L'ensemble de l'architecture est conteneuris√© avec **Docker** pour un d√©ploiement facile et reproductible.

## üöÄ Fonctionnalit√©s

* **Extraction de donn√©es (Scraping) :** R√©cup√©ration automatique du titre, du prix et du lien des livres.
* **Multi-sites :** Architecture capable de g√©rer plusieurs sites web via des "Spiders" d√©di√©s (ex: `produits_decitre.py`, `eyrolles.py`).
* **Nettoyage de donn√©es (Pipeline) :** Conversion des prix (cha√Ænes de caract√®res vers flottants), suppression des symboles devises, etc.
* **Stockage Persistant :** Sauvegarde automatique dans une base de donn√©es MySQL.
* **Interface d'administration :** Visualisation des donn√©es via PhpMyAdmin.
* **Infrastructure Docker :** Lancement de la BDD, du Scraper et de l'interface Admin en une seule commande.

## üõ†Ô∏è Technologies utilis√©es

* **Langage :** Python 3.9+
* **Framework de Scraping :** Scrapy
* **Base de donn√©es :** MySQL 5.7
* **Connecteur :** mysql-connector-python
* **Administration BDD :** PhpMyAdmin
* **Conteneurisation :** Docker & Docker Compose

## üìÇ Structure du Projet

```text
.
‚îú‚îÄ‚îÄ docker-compose.yml      # Orchestration des conteneurs (DB, Scraper, Admin)
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile          # Configuration de l'image MySQL
‚îÇ   ‚îî‚îÄ‚îÄ creation.sql        # Script d'initialisation de la table 'Livre'
‚îú‚îÄ‚îÄ scraper/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile          # Configuration de l'image Python/Scrapy
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt    # D√©pendances Python
‚îÇ   ‚îú‚îÄ‚îÄ scrapy.cfg          # Config globale Scrapy
‚îÇ   ‚îî‚îÄ‚îÄ comparateur/        # Code source du Scrapy
‚îÇ       ‚îú‚îÄ‚îÄ items.py        # D√©finition de la structure des donn√©es
‚îÇ       ‚îú‚îÄ‚îÄ pipelines.py    # Traitement et insertion SQL
‚îÇ       ‚îú‚îÄ‚îÄ settings.py     # R√©glages du robot (User-Agent, d√©lais...)
‚îÇ       ‚îî‚îÄ‚îÄ spiders/        # Les robots (un fichier par site)
‚îÇ           ‚îú‚îÄ‚îÄ produits_decitre.py
‚îÇ           ‚îú‚îÄ‚îÄ produits_eyrolles.py
‚îÇ           ‚îî‚îÄ‚îÄ produits_mollat.py

```

## üìã Pr√©requis

* [Docker Desktop](https://www.docker.com/products/docker-desktop/) install√© sur votre machine.
* Git (pour cloner le projet).

## ‚öôÔ∏è Installation et Lancement

1. **Cloner le d√©p√¥t :**
```bash
git clone [https://github.com/FaridaSintondji/webscraping.git](https://github.com/FaridaSintondji/webscraping.git)
cd webscraping

```


2. **Lancer l'application :**
Cette commande construit les images et lance les conteneurs en arri√®re-plan.
```bash
docker compose up --build -d

```


3. **V√©rifier le fonctionnement :**
Le scraper se lance automatiquement au d√©marrage. Vous pouvez suivre sa progression avec :
```bash
docker compose logs -f scraper

```


4. **Voir les donn√©es (PhpMyAdmin) :**
Ouvrez votre navigateur et allez sur :
üëâ **http://localhost:8081**
* **Serveur :** db
* **Utilisateur :** toto
* **Mot de passe :** toto
* **Base de donn√©es :** Produits -> Table `Livre`



## üõë Commandes Utiles

* **Arr√™ter les conteneurs :**
```bash
docker compose down

```


* **R√©initialiser la base de donn√©es (Grand nettoyage) :**
Si vous avez modifi√© la structure de la table ou si vous voulez effacer toutes les donn√©es pour repartir de z√©ro :
```bash
docker compose down -v  # Le -v supprime le volume de donn√©es
docker compose up --build -d

```


* **Relancer uniquement le scraper (sans √©teindre la BDD) :**
```bash
docker compose restart scraper

```



## üìù Sch√©ma de la Base de Donn√©es

La table `Livre` est structur√©e comme suit :

| Colonne | Type | Description |
| --- | --- | --- |
| id | INT (PK) | Identifiant unique (Auto-inc) |
| titre | TEXT | Titre du livre |
| prix | FLOAT | Prix du livre (ex: 19.50) |
| url | TEXT | Lien vers la page produit |
| site | VARCHAR(50) | Source (ex: "Decitre", "Eyrolles") |

## üë• Auteurs

Ce projet a √©t√© r√©alis√© dans le cadre du cours de Web Scraping & NoSQL.

* **Farida SINTONDJI**
* **A√Øda DIARRASSOUBA**
* **Yomn GERALDO ASSANI**

---

*Derni√®re mise √† jour : D√©cembre 2025*
